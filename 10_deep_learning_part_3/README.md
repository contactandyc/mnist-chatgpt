# My Commentary

This section is all about cleaning up the code generated by ChatGPT.

## Using AnotherCLibrary.com

AnotherCLibrary.com has a malloc/free replacement which keeps track of memory usage and is useful for finding common mistakes.

In attempt1
1. Copy ac_allocator.h/c and ac_common.h into the directory from [AnotherCLibrary github repo](https://github.com/contactandyc/another-c-library/tree/main/src).
2. Replace all calls to free and malloc with ac_free and ac_malloc
3. Replace all calls to calloc with ac_calloc.  ac_calloc takes one parameter.  To make the calls compatible, multiply the two parameters in calloc.
4. Add `#include "ac_allocator.h` to any c file which calls the ac_... methods
5. Add ac_allocator.c to the Makefile

Build the program and run it with ` 2>&1 | sort | uniq -c` added to the end of the command line.

```
% make clean; make
rm -f main.o activation.o matrix.o image_utils.o data_processing.o neural_network.o ac_allocator.o train_and_test
gcc -Wall -Wextra -std=c99 -g -D_AC_DEBUG_MEMORY_=NULL -I. -c main.c -o main.o
gcc -Wall -Wextra -std=c99 -g -D_AC_DEBUG_MEMORY_=NULL -I. -c activation.c -o activation.o
gcc -Wall -Wextra -std=c99 -g -D_AC_DEBUG_MEMORY_=NULL -I. -c matrix.c -o matrix.o
gcc -Wall -Wextra -std=c99 -g -D_AC_DEBUG_MEMORY_=NULL -I. -c image_utils.c -o image_utils.o
gcc -Wall -Wextra -std=c99 -g -D_AC_DEBUG_MEMORY_=NULL -I. -c data_processing.c -o data_processing.o
gcc -Wall -Wextra -std=c99 -g -D_AC_DEBUG_MEMORY_=NULL -I. -c neural_network.c -o neural_network.o
gcc -Wall -Wextra -std=c99 -g -D_AC_DEBUG_MEMORY_=NULL -I. -c ac_allocator.c -o ac_allocator.o
gcc -Wall -Wextra -std=c99 -g -D_AC_DEBUG_MEMORY_=NULL -I. -o train_and_test main.o activation.o matrix.o image_utils.o data_processing.o neural_network.o ac_allocator.o

% ./train_and_test ../../../data/train-images-idx3-ubyte ../../../data/train-labels-idx1-ubyte ../../../data/t10k-images-idx3-ubyte  ../../../data/t10k-labels-idx1-ubyte 2>&1 | sort | uniq -c 
   1 2504510512 byte(s) allocated in 2861277 allocations (114451080 byte(s) overhead)
   1 Epoch 1: loss = 0.86514
   1 Epoch 2: loss = 0.80352
   1 Epoch 3: loss = 0.73679
   1 Epoch 4: loss = 0.72054
   1 Epoch 5: loss = 0.70861
   1 Test Accuracy: 45.00%
3000 activation.c:18: 1024 
3000 activation.c:18: 512 
3100 activation.c:46: 40 
3000 activation.c:76: 256 
3100 activation.c:9: 1024 
3100 activation.c:9: 256 
3100 activation.c:9: 512 
   1 image_utils.c:40: 480000 
   1 image_utils.c:40: 80000 
70000 image_utils.c:52: 784 
576000 matrix.c:10: 1024 
798000 matrix.c:10: 256 
384000 matrix.c:10: 3136 
192000 matrix.c:10: 40 
768000 matrix.c:10: 512 
3000 matrix.c:59: 1024 
3000 matrix.c:59: 256 
3000 matrix.c:59: 512 
3000 matrix.c:79: 1024 
3000 matrix.c:79: 256 
3000 matrix.c:79: 512 
6000 matrix.c:7: 1024 
6000 matrix.c:7: 2048 
6000 matrix.c:7: 512 
3000 matrix.c:7: 80 
3100 matrix.c:98: 1024 
3100 matrix.c:98: 256 
3100 matrix.c:98: 40 
3100 matrix.c:98: 512 
   1 neural_network.c:10: 16 
   1 neural_network.c:19: 1024 
   1 neural_network.c:19: 256 
   1 neural_network.c:19: 40 
   1 neural_network.c:19: 512 
   1 neural_network.c:28: 1024 
   1 neural_network.c:28: 2048 
   1 neural_network.c:28: 512 
   1 neural_network.c:28: 80 
  64 neural_network.c:30: 1024 
  10 neural_network.c:30: 256 
 128 neural_network.c:30: 3136 
 256 neural_network.c:30: 512 
   4 neural_network.c:39: 48 
   1 neural_network.c:54: 1024 
   1 neural_network.c:54: 256 
   1 neural_network.c:54: 40 
   1 neural_network.c:54: 512 
```

This shows the frequency, line/location and the number of bytes allocated at the given location.  A lot of the allocations are happening in the matrix.c/h.  To improve this, new arrays and matrices are added to the layers that can be reused.

```c
typedef struct {
    int size;
    int inputs_size;
    float* biases;
    float** weights;
    float* (*activation_function)(float*, int);
    float* (*activation_derivative)(float*, int);
    float* outputs;
} Layer;
```

becomes

```c
typedef struct {
    int size;
    int inputs_size;
    float* biases;
    float** weights;
    float** gradients;
    float** transposed;
    float* output_error;
    void (*activation_function)(float*, int);
    void (*activation_derivative)(float*, int);
    float* outputs;
} Layer;
```

`gradients` which is a size x inputs_size array and is used by backward propagation.
`transposed` is used to transpose the `weights` matrix and is inputs_size x size.
`output_error` is used to track the difference between the output and target (or the next layer).

The activation functions just manipulate the inputs in place.  activation.c/h need changed.

The next change is to remove the allocations from matrix by passing a result array or matrix to the functions.

A new function

```c
void freeNeuralNetwork(NeuralNetwork *network);
```

is introduced in neural_network.h

